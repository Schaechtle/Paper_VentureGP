\documentclass[twoside,11pt]{article}
\usepackage{listings}
\usepackage[svgnames,dvipsnames]{xcolor} % Specify colors by their 'svgnames', for a full list of all colors available see here: http://www.latextemplates.com/svgnames-colors
\usepackage{etoolbox}
\usepackage{jmlr2e}
%\usepackage{nips15submit_e,times}
\usepackage{hyperref}
\usepackage{url}
\usepackage{tcolorbox}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{bm}
\usepackage{amsmath,amssymb}
\usepackage{natbib}
\usepackage[nolist]{acronym}
%\pgfplotsset{compat=1.9}
\usepackage[framemethod=TikZ]{mdframed}% http://ctan.org/pkg/mdframed
\usepackage{graphicx}
\usepackage[abs]{overpic}
\usepackage{caption}
\usepackage{subcaption}

\usepackage{fancyvrb}
\usepackage{placeins}

% new frames
\usepackage{mdframed}

% to make compatible with Ben's source
\usepackage[inline]{asymptote}
\usepackage{mathtools}
\usepackage{inconsolata}
\usepackage{placeins}
\usepackage{setspace}

\usepackage{algorithm}
\usepackage{algpseudocode}

\usepackage[inline]{asymptote}
\usetikzlibrary{arrows}

\usepackage{enumitem}

\usepackage{multicol}


\begin{asydef}
defaultpen(fontsize(11));
\end{asydef}

\usetikzlibrary{tikzmark}
\usetikzlibrary{bayesnet}
\usetikzlibrary{pgfplots.groupplots}

\newcommand{\gpmem}{\texttt{gpmem}}
\newcommand{\emu}{{\textrm{emu}}}
\newcommand{\restr}{{\textrm{restr}}}
\newcommand{\true}{{\textrm{true}}}
\newcommand{\rmnew}{{\textrm{new}}}
\newcommand{\past}{{\textrm{past}}}
\newcommand{\prior}{{\textrm{prior}}}
\newcommand{\noisy}{{\textrm{noisy}}}
\newcommand{\noise}{{\textrm{noise}}}
\newcommand{\sigmanoise}{\sigma_{\text{noise}}}
\newcommand{\Acal}{\mathcal{X}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\xprime}{\mathbf{x}^\prime}
\newcommand{\yprime}{\mathbf{y}^\prime}
\newcommand{\yprimetop}{\mathbf{y}^{\prime \top}}
\newcommand{\xstar}{\mathbf{x}^*}
\newcommand{\ystar}{\mathbf{y}^*}
\newcommand{\abf}{\mathbf{x}}
\newcommand{\tbf}{\mathbf{t}}
\newcommand{\fbf}{\mathbf{f}}
\newcommand{\hbf}{\mathbf{h}}
\newcommand{\rbf}{\mathbf{y}}
\newcommand{\wbf}{\mathbf{w}}
\newcommand{\xbf}{\mathbf{x}}
\newcommand{\Mbf}{\mathbf{M}}
\newcommand{\Dbf}{\mathbf{D}}
\newcommand{\ybf}{\mathbf{y}}
\newcommand{\Kbf}{\mathbf{K}}
\newcommand{\Lbf}{\mathbf{L}}
\newcommand{\Sbf}{\mathbf{S}}
\newcommand{\Ktheta}{\mathbf{K}_{\bm{\theta}}}
\newcommand{\ktheta}{k_{\bm{\theta}}}
\newcommand{\Kpost}{\mathbf{K}_{\bm{\theta}}^\text{post}}
\newcommand{\mupost}{\bm{\mu}_{\bm{\theta}}^\text{post}}
\newcommand{\thetabf}{\bm{\theta}}
\newcommand{\Omegabf}{\bm{\Omega}}
\newcommand{\midtheta}{\mid \bm{\theta}}
\newcommand{\Ibf}{\mathbf{I}}
\newcommand{\mubf}{\bm{\mu}}
\newcommand{\Krv}{\bm{\mathcal{K}}}
\newcommand{\Klin}{K^\text{linear}}
\newcommand{\Kper}{K^\text{periodic}}
\newcommand{\klin}{k^\text{linear}}
\newcommand{\kwn}{k^\text{wn}}
\newcommand{\kper}{k^\text{periodic}}
\newcommand{\kse}{k^\text{se}}
\newcommand{\Kse}{K^\text{se}}
\newcommand{\Ksrv}{\bm{\mathcal{K}}_\text{Struct}}
\newcommand{\Struct}{\text{Struct}}
\newcommand{\Simplify}{\text{Simplify}}
\newcommand{\Parse}{\text{Parse}}
%k\newcommand{\kper}{k^\text{periodic}}



\newcommand{\pn}[1]{\left( #1 \right)}
\newcommand{\bkt}[1]{\left[ #1 \right]}
\newcommand{\br}[1]{\left\{ #1 \right\}}
\newcommand{\abs}[1]{\left\lvert #1 \right\rvert}
\newcommand{\Ebkt}[2][]{\mathbb{E}_{#1}\bkt{#2}}
\newcommand{\mvert}{\ \middle\vert\ }

\newcommand{\bmat}[1]{\begin{bmatrix} #1 \end{bmatrix}}

\newcommand{\Ncal}{\mathcal{N}}
\newcommand{\ftt}{\texttt{f}}
\newcommand{\gtt}{\texttt{g}}
\newcommand{\xtt}{\texttt{x}}
\newcommand{\mm}{\texttt{mem\&em}}

\newcommand{\quadmem}{\texttt{quadmem}}
\newcommand{\compute}{{\textrm{compute}}}
\newcommand{\probe}{{\textrm{probe}}}


\newcommand{\rmnext}{{\textrm{next}}}


\newcommand{\noiseless}{{\textrm{noiseless}}}
\newcommand{\proposal}{{\textrm{proposal}}}
\newcommand{\update}{{\textrm{update}}}
\newcommand{\search}{{\textrm{search}}}
\newcommand{\accept}{{\textrm{accept}}}
\newcommand{\current}{{\textrm{current}}}
\newcommand{\MC}{{\textrm{MC}}}
\newcommand{\MH}{{\textrm{MH}}}
\newcommand{\avg}{{\textrm{avg}}}
\newcommand{\reg}{{\textrm{reg}}}
\newcommand{\ttheta}{\vartheta}
\newcommand{\muhat}{\widehat{\mu}}

\newcommand{\xtil}{\widetilde{x}}
\newcommand{\ytil}{\widetilde{y}}

\newcommand{\s}[2]{#2^{(#1)}}
\newcommand{\GP}{\mathcal{GP}}
\newcommand{\propstd}{\texttt{propstd}}

\newcommand{\paperOrChapter}{paper}

\DeclareMathOperator*{\Cov}{Cov}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator{\Uniform}{Uniform}
\DeclareMathOperator{\SE}{SE}

\newcommand{\myparagraph}[1]{\paragraph{#1}\mbox{}\\}

\begin{acronym}
\acro{GP} {Gaussian Processes}
\acro{MAP} {Maximum a posteriori}
\acro{MCMC} {Markov Chain Monte Carlo}
\acro{MDP} {Markov Decision Processes} 
\acro{MH} {Metropolis-Hastings}
\acro{SP} {Stochastic Process}
\acro{CCF} {Cosmic Calibration Framework}
\end{acronym}

\setlength{\multicolsep}{0.0pt plus 2.0pt minus 1.5pt}
% The following is a modified version of what's available on Wikibooks,
% http://en.wikibooks.org/wiki/LaTeX/Source_Code_Listings
  \definecolor{mygreen}{rgb}{0,0.6,0}
  \definecolor{mygray}{rgb}{0.5,0.5,0.5}
  \definecolor{mymauve}{rgb}{0.58,0,0.82}
  \definecolor{mygreen}{rgb}{0,0.4,0}
  \definecolor{mypurple}{rgb}{0.38,0,0.83}
  \definecolor{myorange}{rgb}{0.75,0.3,0}
  \definecolor{myblue}{RGB}{76,114,176}

 \lstdefinelanguage{Venture}{
    alsoletter={\&,=,!,?}
    keywordstyle=\color{black},
    morecomment=[l]{//},
    commentstyle=\color{mygreen},
    keywordstyle=[2]\color{DarkRed},
    keywords=[2]{assume,predict,infer,observe,define,assume_list,sample,call_back,for},
    keywordstyle=[3]\color{myorange},
    keywords=[3]{if,then,else,lambda,tag,do,proc,repeat,run,pass,true,false,quote,default,all,one,begin,let,lte,letrec,set!},
    keywordstyle=[4]\color{mypurple},
    keywords=[4]{flip,normal,flip,bernoulli,uniform_continuous,uniform_structure,uniform_discrete,gamma,mh,rejection,array,max,length,list,first,second,gridsearch_argmax,apply,add_funcs,mult_funcs,subset,lookup,size,mem\&em,contains,stats,map,mapv,gpmem,quadmem,make_whitenoise, mem,make_gp,make_const_func,make_squaredexp,draw_gp_curves,exclude,closest_point,contents,set_contents,contents_changed?,contents_changed,mark_recently_changed,peek,increment,tail,repeatO,confine,return,print,get_neal_blackbox,get_neal_data_xs,get_data_xs,size,get_bayesopt_blackbox},
    literate=%
    *{0}{{{\color{DarkBlue}0}}}1
    {1}{{{\color{DarkBlue}1}}}1
    {2}{{{\color{DarkBlue}2}}}1
    {3}{{{\color{DarkBlue}3}}}1
    {4}{{{\color{DarkBlue}4}}}1
    {5}{{{\color{DarkBlue}5}}}1
    {6}{{{\color{DarkBlue}6}}}1
    {7}{{{\color{DarkBlue}7}}}1
    {8}{{{\color{DarkBlue}8}}}1
    {9}{{{\color{DarkBlue}9}}}1,
  }
  \lstset{
    basicstyle=\singlespacing\ttfamily,
    language=Venture,
    showstringspaces=false,
  }

\newdimen\linenumbersep

\newcommand{\linenumber}[1]{%
  \linenumbersep 4pt%
  \advance\linenumbersep\mdflength{innerleftmargin}%
  \advance\linenumbersep\mdflength{innerlinewidth}%
  \advance\linenumbersep\mdflength{middlelinewidth}%
  \advance\linenumbersep\mdflength{outerlinewidth}%
  \advance\linenumbersep\mdflength{linewidth}%
  \makebox[0pt][r]{{\rmfamily\tiny#1}\hspace*{\linenumbersep}}}
\small

\let\OldStatex\Statex
\renewcommand{\Statex}[1][3]{%
  \setlength\@tempdima{\algorithmicindent}%
  \OldStatex\hskip\dimexpr#1\@tempdima\relax}

%\jmlrheading{}{}{}{}{}{}

% Short headings should be running head and authors last names

\ShortHeadings{Probabilistic Programming with Gaussian Process Memoization}{}
\firstpageno{1}
\usepackage{lineno}
\linenumbers
\setlength\linenumbersep{5pt}
\renewcommand\linenumberfont{\normalfont\tiny\sffamily\color{gray}}


\begin{document}
\title{Probabilistic Programming with Gaussian Process Memoization}


\author{\name Ulrich Schaechtle \email ulrich.schaechtle@rhul.ac.uk \\
	      \addr Department of Computer Science\\
              Royal Holloway, University of London
       \AND \name Ben Zinberg \email bzinberg@mit.edu \\
              \addr Computer Science and Artificial Intelligence Laboratory\\
              Massachusetts Institute of Technology
       \AND \name Alexey Radul \email axofch@gmail.com \\
              \addr Computer Science and Artificial Intelligence Laboratory\\
              Massachusetts Institute of Technology
       \AND \name Kostas Stathis \email kostas.stathis@rhul.ac.uk\\
              \addr Department of Computer Science\\
       Royal Holloway, University of London
       \AND \name Vikash K. Mansinghka \email vkm@mit.edu \\
	      \addr Computer Science and Artificial Intelligence Laboratory\\
	      Massachusetts Institute of Technology
} 

       \editor{N.A.}

\maketitle


\begin{abstract}
This paper describes the {\em Gaussian process memoizer}, a probabilistic programming technique that uses Gaussian processes to provide a statistical alternative to memorization. Memoizing a target procedure results in a “self-caching” wrapper that remembers previously computed values. Gaussian process memoization additionally produces a statistical emulator based on a Gaussian process whose predictions automatically improve whenever a new value of the target procedure becomes available. This paper also introduces  an efficient implementation, named {\tt gpmem}, that can use kernels given by a broad class of probabilistic programs. The flexibility of {\tt gpmem} is illustrated via three applications: (i) GP regression with hierarchical hyper-parameter learning, (ii) Bayesian structure learning via compositional kernels generated by a probabilistic grammar, and (iii) a bandit formulation of Bayesian optimization with automatic inference and action selection. All applications share a single 50-line Python library and require fewer than 20 lines of probabilistic code each.
\end{abstract}

\section{Introduction}
\input{sections/VenGPIntroduction.tex}
%\subsection{Background on Probabilistic Programming}\label{sec:pp-background}
%\input{sections/Background_on_PP.tex}
%\myparagraph{Traces and Interactivity}
%\input{sections/Traces_and_Interactivity.tex}
%\subsection{Memoization}

%\subsection{Venture}
%\input{sections/VentureLanguage.tex}

\section{Background on Gaussian Processes}
\input{sections/GP.tex}

%\subsection{A Bayesian interpretation}
%\input{sections/MHvsMAP.tex}

\section{Gaussian Process Memoization in Venture}
\input{sections/gpmem.tex}

\section{Applications}
This paper illustrates the flexibility of \gpmem\ by showing how it can concisely encode three different applications of \ac{GP}s.
The first is a standard example from hierarchical Bayesian statistics, where Bayesian inference over a hierarchical hyper-prior is used to provide a curve-fitting methodology that is robust to outliers.
The second is a structure learning application from probabilistic artificial intelligence, where \ac{GP}s are used to discover qualitative structure in time series data.
The third is a reinforcement learning application, where \ac{GP}s are used as part of a Thompson sampling formulation of Bayesian optimization for general real-valued objective functions with real inputs.

\subsection{Nonlinear regression in the presence of outliers}
\input{sections/hyperparameters.tex}
%\subsubsection{Broader applicability of \gpmem}\label{sec:gpmem-broader}
%\input{sections/applicability.tex}
\subsection{Discovering qualitative structure from time series data}\label{sec:structurelearning}
\input{sections/StructureLearning.tex}

\subsection{Bayesian optimization}

\label{sec:thompson}



\input{sections/Bayesian_Optimization_using_TS.tex}
%input{sections/BayesianOptimization.tex}
%\subsubsection{Thompson sampling framework}
%\input{sections/TSframework.tex}
%\subsubsection{Thompson sampling in Venture}
%\input{sections/TSVenture.tex}
%\subsubsection{Implementation with \gpmem}
%\input{sections/TSimplementation.tex}
\section{Discussion}
\input{sections/Conclusion.tex}

\newpage
\section*{Appendix}
\subsection*{A Covariance Functions}
\input{sections/Appendix_Cov.tex}

\subsection*{B Covariance Simplification}
\input{sections/Appendix_Simplification.tex}

\subsection*{C The Struct-Operator}
\input{sections/Appendix_Struct.tex}

\subsection*{D Additional Venture Code}
\input{sections/Appendix_SE_kernel.tex}
\newpage
\subsection*{E Glossary}
\input{sections/glossary.tex}
%\subsection*{C Additional Structure Learning Results}
%\input{sections/Appendix_Structure_Results.tex}

\newpage
\bibliography{September2015}
\bibliographystyle{apalike}
\end{document}
