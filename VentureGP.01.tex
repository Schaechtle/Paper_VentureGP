\documentclass[twoside,11pt]{article}
\usepackage{listings}
\usepackage[svgnames,dvipsnames]{xcolor} % Specify colors by their 'svgnames', for a full list of all colors available see here: http://www.latextemplates.com/svgnames-colors
\usepackage{etoolbox}
\usepackage{jmlr2e}
%\usepackage{nips15submit_e,times}
\usepackage{hyperref}
\usepackage{url}
\usepackage{tcolorbox}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{bm}
\usepackage{amsmath,amssymb}
\usepackage{natbib}
\usepackage[nolist]{acronym}
%\pgfplotsset{compat=1.9}
\usepackage[framemethod=TikZ]{mdframed}% http://ctan.org/pkg/mdframed
\usepackage{graphicx}

\usepackage{caption}
\usepackage{subcaption}

\usepackage{fancyvrb}
\usepackage{placeins}

% new frames
\usepackage{mdframed}

% to make compatible with Ben's source
\usepackage[inline]{asymptote}
\usepackage{mathtools}
\usepackage{inconsolata}
\usepackage{placeins}
\usepackage{setspace}

\usepackage{algorithm}
\usepackage{algpseudocode}

\usepackage[inline]{asymptote}
\usetikzlibrary{arrows}

\usepackage{enumitem}

\usepackage{multicol}


\begin{asydef}
defaultpen(fontsize(11));
\end{asydef}

\usetikzlibrary{tikzmark}
\usetikzlibrary{bayesnet}
\usetikzlibrary{pgfplots.groupplots}

\newcommand{\gpmem}{\texttt{gpmem}}
\newcommand{\emu}{{\textrm{emu}}}
\newcommand{\restr}{{\textrm{restr}}}
\newcommand{\true}{{\textrm{true}}}
\newcommand{\rmnew}{{\textrm{new}}}
\newcommand{\past}{{\textrm{past}}}
\newcommand{\prior}{{\textrm{prior}}}
\newcommand{\noisy}{{\textrm{noisy}}}
\newcommand{\noise}{{\textrm{noise}}}

\newcommand{\Acal}{\mathcal{A}}
\newcommand{\R}{\mathbb{R}}

\newcommand{\abf}{\mathbf{a}}
\newcommand{\fbf}{\mathbf{f}}
\newcommand{\hbf}{\mathbf{h}}
\newcommand{\rbf}{\mathbf{r}}
\newcommand{\wbf}{\mathbf{w}}
\newcommand{\xbf}{\mathbf{x}}
\newcommand{\ybf}{\mathbf{y}}
\newcommand{\Kbf}{\mathbf{K}}
\newcommand{\Ibf}{\mathbf{I}}
\newcommand{\mubf}{\bm{\mu}}

\newcommand{\pn}[1]{\left( #1 \right)}
\newcommand{\bkt}[1]{\left[ #1 \right]}
\newcommand{\br}[1]{\left\{ #1 \right\}}
\newcommand{\abs}[1]{\left\lvert #1 \right\rvert}
\newcommand{\Ebkt}[2][]{\mathbb{E}_{#1}\bkt{#2}}
\newcommand{\mvert}{\ \middle\vert\ }

\newcommand{\bmat}[1]{\begin{bmatrix} #1 \end{bmatrix}}

\newcommand{\Ncal}{\mathcal{N}}
\newcommand{\ftt}{\texttt{f}}
\newcommand{\gtt}{\texttt{g}}
\newcommand{\xtt}{\texttt{x}}
\newcommand{\mm}{\texttt{mem\&em}}

\newcommand{\quadmem}{\texttt{quadmem}}
\newcommand{\compute}{{\textrm{compute}}}
\newcommand{\probe}{{\textrm{probe}}}


\newcommand{\rmnext}{{\textrm{next}}}


\newcommand{\noiseless}{{\textrm{noiseless}}}
\newcommand{\proposal}{{\textrm{proposal}}}
\newcommand{\update}{{\textrm{update}}}
\newcommand{\search}{{\textrm{search}}}
\newcommand{\accept}{{\textrm{accept}}}
\newcommand{\current}{{\textrm{current}}}
\newcommand{\MC}{{\textrm{MC}}}
\newcommand{\MH}{{\textrm{MH}}}
\newcommand{\avg}{{\textrm{avg}}}
\newcommand{\reg}{{\textrm{reg}}}
\newcommand{\ttheta}{\vartheta}
\newcommand{\muhat}{\widehat{\mu}}

\newcommand{\xtil}{\widetilde{x}}
\newcommand{\ytil}{\widetilde{y}}

\newcommand{\s}[2]{#2^{(#1)}}
\newcommand{\GP}{\mathcal{GP}}
\newcommand{\propstd}{\texttt{propstd}}

\newcommand{\paperOrChapter}{paper}

\DeclareMathOperator*{\Cov}{Cov}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator{\Uniform}{Uniform}
\DeclareMathOperator{\SE}{SE}

\newcommand{\myparagraph}[1]{\paragraph{#1}\mbox{}\\}

\begin{acronym}
\acro{GP} {Gaussian Processes}
\acro{MAP} {Maximum a posteriori}
\acro{MCMC} {Markov Chain Monte Carlo}
\acro{MDP} {Markov Decision Processes} 
\acro{MH} {Metropolis-Hastings}
\acro{SP} {Stochastic Process}
\end{acronym}

\setlength{\multicolsep}{0.0pt plus 2.0pt minus 1.5pt}
% The following is a modified version of what's available on Wikibooks,
% http://en.wikibooks.org/wiki/LaTeX/Source_Code_Listings
  \definecolor{mygreen}{rgb}{0,0.6,0}
  \definecolor{mygray}{rgb}{0.5,0.5,0.5}
  \definecolor{mymauve}{rgb}{0.58,0,0.82}
  \definecolor{mygreen}{rgb}{0,0.4,0}
  \definecolor{mypurple}{rgb}{0.38,0,0.83}
  \definecolor{myorange}{rgb}{0.75,0.3,0}
  \definecolor{myblue}{RGB}{76,114,176}

 \lstdefinelanguage{Venture}{
    alsoletter={\&,=,!,?}
    keywordstyle=\color{black},
    morecomment=[l]{//},
    commentstyle=\color{mygreen},
    keywordstyle=[2]\color{DarkRed},
    keywords=[2]{assume,predict,infer,observe,define,assume_list,sample,call_back,for},
    keywordstyle=[3]\color{myorange},
    keywords=[3]{if,then,else,lambda,tag,do,proc,repeat,run,pass,true,false,quote,default,all,one,begin,let,lte,letrec,set!},
    keywordstyle=[4]\color{mypurple},
    keywords=[4]{flip,normal,flip,bernoulli,uniform_continuous,uniform_structure,uniform_discrete,gamma,mh,rejection,array,max,length,list,first,second,gridsearch_argmax,apply,add_funcs,mult_funcs,subset,lookup,size,mem\&em,contains,stats,map,mapv,gpmem,quadmem,make_whitenoise, mem,make_gp,make_const_func,make_squaredexp,draw_gp_curves,exclude,closest_point,contents,set_contents,contents_changed?,contents_changed,mark_recently_changed,peek,increment,tail,repeatO,confine,return,print,get_neal_blackbox,get_neal_data_xs,get_data_xs,size,get_bayesopt_blackbox},
    literate=%
    *{0}{{{\color{DarkBlue}0}}}1
    {1}{{{\color{DarkBlue}1}}}1
    {2}{{{\color{DarkBlue}2}}}1
    {3}{{{\color{DarkBlue}3}}}1
    {4}{{{\color{DarkBlue}4}}}1
    {5}{{{\color{DarkBlue}5}}}1
    {6}{{{\color{DarkBlue}6}}}1
    {7}{{{\color{DarkBlue}7}}}1
    {8}{{{\color{DarkBlue}8}}}1
    {9}{{{\color{DarkBlue}9}}}1,
  }
  \lstset{
    basicstyle=\singlespacing\ttfamily,
    language=Venture,
    showstringspaces=false,
  }

\newdimen\linenumbersep

\newcommand{\linenumber}[1]{%
  \linenumbersep 4pt%
  \advance\linenumbersep\mdflength{innerleftmargin}%
  \advance\linenumbersep\mdflength{innerlinewidth}%
  \advance\linenumbersep\mdflength{middlelinewidth}%
  \advance\linenumbersep\mdflength{outerlinewidth}%
  \advance\linenumbersep\mdflength{linewidth}%
  \makebox[0pt][r]{{\rmfamily\tiny#1}\hspace*{\linenumbersep}}}
\small

\let\OldStatex\Statex
\renewcommand{\Statex}[1][3]{%
  \setlength\@tempdima{\algorithmicindent}%
  \OldStatex\hskip\dimexpr#1\@tempdima\relax}

%\jmlrheading{}{}{}{}{}{}

% Short headings should be running head and authors last names

\ShortHeadings{Probabilistic Programming with Gaussian Process Memoization}{}
\firstpageno{1}


\begin{document}
\title{Probabilistic Programming with Gaussian Process Memoization}


\author{\name Ulrich Schaechtle \email ulrich.schaechtle@rhul.ac.uk \\
	      \addr Department of Computer Science\\
              Royal Holloway, University of London
       \AND \name Ben Zinberg \email bzinberg@mit.edu \\
              \addr Computer Science and Artificial Intelligence Laboratory\\
              Massachusetts Institute of Technology
       \AND \name Alexey Radul \email axofch@gmail.com \\
              \addr Computer Science and Artificial Intelligence Laboratory\\
              Massachusetts Institute of Technology
       \AND \name Kostas Stathis \email kostas.stathis@rhul.ac.uk\\
              \addr Department of Computer Science\\
       Royal Holloway, University of London
       \AND \name Vikash K. Mansinghka \email vkm@mit.edu \\
	      \addr Computer Science and Artificial Intelligence Laboratory\\
	      Massachusetts Institute of Technology
} 

       \editor{N.A.}

\maketitle


\begin{abstract}
This paper describes the {\em Gaussian process memoizer}, a probabilistic programming technique that uses Gaussian processes to provide a statistical alternative to memorization. Memoizing a target procedure results in a “self-caching” wrapper that remembers previously computed values. Gaussian process memoization additionally produces a statistical emulator based on a Gaussian process whose predictions automatically improve whenever a new value of the target procedure becomes available. This paper also introduces  an efficient implementation, named {\tt gpmem}, that can use kernels given by a broad class of probabilistic programs. The flexibility of {\tt gpmem} is illustrated via three applications: (i) GP regression with hierarchical hyper-parameter learning, (ii) Bayesian structure learning via compositional kernels generated by a probabilistic grammar, and (iii) a bandit formulation of Bayesian optimization with automatic inference and action selection. All applications share a single 50-line Python library and require fewer than 20 lines of probabilistic code each.
\end{abstract}

\section{Introduction}
\input{sections/VenGPIntroduction.tex}
%\subsection{Background on Probabilistic Programming}\label{sec:pp-background}
%\input{sections/Background_on_PP.tex}
%\myparagraph{Traces and Interactivity}
%\input{sections/Traces_and_Interactivity.tex}
%\subsection{Memoization}

%\subsection{Venture}
%\input{sections/VentureLanguage.tex}

\section{Background on Gaussian Processes}
\input{sections/GP.tex}

%\subsection{A Bayesian interpretation}
%\input{sections/MHvsMAP.tex}

\subsection{The \gpmem\ construct}
\input{sections/Memoization.tex}
\input{sections/Statistical_Memoizers.tex}
%\input{sections/gpmem.tex}

\input{sections/data_modelling.tex}
\newpage
\section{Applications}
\gpmem\ is an elegant linguistic framework for function learning-related tasks.
The technique allows language constructs from programming to help express models
which would be cumbersome to express in statistics notation.
We will now illustrate this with three example applications. 

\subsection{Nonlinear regression in the presence of outliers}
\input{sections/hyperparameters.tex}
%\subsubsection{Broader applicability of \gpmem}\label{sec:gpmem-broader}
%\input{sections/applicability.tex}
\subsection{Discovering qualitative structure from time series data}\label{sec:structurelearning}
\input{sections/StructureLearning.tex}

\subsection{Bayesian optimization}

\label{sec:thompson}



\input{sections/Bayesian_Optimization_using_TS.tex}
%input{sections/BayesianOptimization.tex}
%\subsubsection{Thompson sampling framework}
%\input{sections/TSframework.tex}
%\subsubsection{Thompson sampling in Venture}
%\input{sections/TSVenture.tex}
%\subsubsection{Implementation with \gpmem}
%\input{sections/TSimplementation.tex}
\section{Discussion}
\input{sections/Conclusion.tex}

\newpage
\section*{Appendix}
\subsection*{A Covariance Functions}
\input{sections/Appendix_Cov.tex}

\subsection*{B Covariance Simplification}
\input{sections/Appendix_Simplification.tex}

\subsection*{C Glossary}
\input{sections/glossary.tex}
%\subsection*{C Additional Structure Learning Results}
%\input{sections/Appendix_Structure_Results.tex}

\newpage
\bibliography{September2015}
\bibliographystyle{apalike}
\end{document}
