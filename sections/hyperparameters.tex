We can apply \gpmem\ for regression in a hierarchical Bayesian setting
(Fig. \ref{fig:neal_tutorial}).  
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}
\input{figs/neal_tutorial.tex}
\put(-410,230){(b)}
\put(-410,170){(c)}
\put(-410,90){(d)}
\put(-410,-10){(e)}
\put(-410,-110){(f)}
\put(-410,-210){(g)}
\caption{\footnotesize Regression with outliers and hierarchical prior
structure. The code for the hyper-priors is omited here but provided in Appendix
D}
\label{fig:neal_tutorial}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
In a Bayesian treatment of  hyper-parameter learning for \ac{GP}s,
we can write the posterior probability of the hyper-parameters of a GP  (Fig.
\ref{fig:neal_tutorial}, (a)) given covariance function $\Krv=k$ as:
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{equation}
\label{eq:hyperProbability}
P(\thetabf=\{sf,\ell,\sigma\} \mid \mathbf{D},\Krv ) = \frac{P(\mathbf{D} \mid
\thetabf, \Krv)P(\thetabf \mid \Krv) }{P(\mathbf{D} \mid
\Krv)}
\end{equation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
where $\mathbf{D} = \{\xbf, \ybf\}$ is a training data set and $\Krv$ is treated
as a random variable over covariance functions. Since we can apply
\gpmem\ to any process or procedure, it can be used in situations where only a data
set is available via a look-up function $\texttt{f\_look\_up}$.
In fact, we demonstrate \gpmem's application to regression using an example where
the data was generated by a function which is not available, that is, we do not
provide the synthetic function to \gpmem\ but only a data set (Fig.
\ref{fig:neal_tutorial} (b)).
This function, $f_\text{true}$, is taken from a paper on the
treatment of outliers with hierarchical Bayesian hyper-priors for
\ac{GP}s~\citep{neal1997monte}:
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{equation}
f_\text{true}(x) =  0.3 + 0.4 x + 0.5 \sin(2.7x) + \frac{1.1}{(1+ x^2)} + \eta
\;\;\; with\;\;\eta \sim \mathcal{N}(0,\sigmanoise).
\end{equation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
We synthetically generate outliers by setting $\sigmanoise = 0.1$ in $95\%$ of
the cases and to $\sigmanoise = 1$ in the remaining cases. 
Instead of accessing the $f_\text{true}$ directly, we are accessing the $\texttt{data}$ in form of
a a two dimensional $\texttt{array}$ with $\texttt{f\_look\_up}$.

We set $\Krv = k^{\text{se}+\text{wn}}$ and parameterize it with $\bm{\theta}=\{sf,\ell,\sigma\}$.
For these hyper-parameters, Neals work suggests a hierarchical system for
for hyper-parameterization.
Here, we draw hyper-parameters from $\Gamma$ distributions:
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{equation}
\label{eq:hyper-ell}
\ell \sim \Gamma(\alpha_1,\beta_1),\;\sigma \sim \Gamma(\alpha_2,\beta_2)
\end{equation} 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
and in turn sample the $\alpha$ and $\beta$ from $\Gamma$ distributions as well:
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{equation}
\label{eq:hyper-alpha}
\alpha_1 \sim \Gamma(\alpha^1_{\alpha},\beta^1_{ \alpha } ),\; \alpha_2 \sim \Gamma(\alpha^2_{\alpha},\beta^2_{\alpha}),\cdots
\end{equation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
We model this in Venture as illustrated in Fig. \ref{fig:neal_tutorial} (c),
using the build-in \ac{SP} $\texttt{gamma}$. Note that we omit the prior distributions of (\ref{eq:hyper-alpha}) due limited space in the tutorial.

In Fig. \ref{fig:neal_tutorial}, panel (d), we see that $k^{\text{se}+\text{wn}}$
is defined as a composite covariance function. It is the sum ($\texttt{add\_funcs}$) of
an squared exponential kernel ($\texttt{make\_squaredexp}$) and a white noise
($\kwn$, Appendix A)
kernel which is implemented with $\texttt{make\_whitenoise}$\footnote{Note
that in Neal's work \citeyearpar{neal1997monte} the sum of an SE
plus a constant kernel is used. We use a WN kernel for illustrative purposes
instead.}. 
We then initialize \gpmem\ feeding it with $\texttt{composite\_covariance}$ and the data
look-up function $\texttt{f\_look\_up}$. 
We sample from the prior $\ystar$ with random parameters $\texttt{sf,l}$ and $\texttt{sigma}$ and 
without any observations available.
We depict those samples on the right (red), alongside the true function that generated the data (blue) and
the data points we have available in the data set (black).

We can incorporate observations using both \texttt{observe} and \texttt{predict} (Fig. \ref{fig:neal_tutorial} (e)).
When we subsequently sample $\yprime$ from the emulator with
$\mathcal{N}(\mupost,\Kpost)$, we can see that the \ac{GP} posterior incorporates knowledge 
about the $\texttt{data}$. Yet, the hyper-parameters $\texttt{sf,l}$ and $\texttt{sigma}$ are still
random, so the emulator does not capture the true underlying dynamics
($f_\text{true}$) of the \texttt{data} correctly. 

Next, we demonstrate how we can capture these underlying dynamics within only
100  nested \ac{MH} steps on the hyper-parameters to get a good approximation
for their posterior $\yprime$ (Fig. \ref{fig:neal_tutorial} (f)).
We say nested because we first take two sweeps in the scope
$\texttt{hyperhyper}$ which characterizes (\ref{eq:hyper-alpha}) and then one
sweep on the scope $\texttt{hyper}$ which characterizes (\ref{eq:hyper-ell}).
This is repeated 100 using $\texttt{repeat( 100, do(}\cdots\;$.
Note that Neal devises an additional noise model and performs a large number of Hybrid-Monte Carlo and Gibbs steps to achieve this, whereas inference in Venture with \gpmem\ is merely one line of code. 

Finally, we can change our inference strategy altogether. If we decide that instead of
following a Bayesian sampling approach, we would like to perform empirical optimization,
we do this by only changing one line of code, deploying $\texttt{gradient-ascent}$ instead
of $\texttt{mh}$ (Fig. \ref{fig:neal_tutorial} (g)). 

