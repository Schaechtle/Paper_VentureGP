
The Venture procedure \texttt{make-gp} takes as input a mean function and a covariance function, and outputs a procedure for sampling from a Gaussian process.
In effect, each call to this procedure samples from \eqref{eq:gpsampler} conditioned on the return values of all previous samples.
\texttt{make-gp} allows us to perform GP inference in Venture with only a few lines of code.
We can concisely express a wide variety of GPs: simple smoothing with fixed hyper-parameters, or a prior on hyper-parameters, or a custom covariance function.
Inference on hyper-parameters can be performed using Venture's built-in MH operator or a custom inference strategy.

Venture code to create and sample from a GP with a smoothing kernel and hyperparameters is shown in Listing \ref{alg:gpNeal}.
\begin{minipage}{\linewidth}
\small
\belowcaptionskip=-10pt
\begin{lstlisting}[frame=single,mathescape,label=alg:gpNeal,basicstyle=\selectfont\ttfamily]
// HYPER-PARAMETERS
assume log_sf = tag('hyper, log(gamma(1,1))))
assume log_l = tag('hyper, log(gamma(1,1))))

// COVARIANCE FUNCTION
assume se = make_squaredexp(log_sf, log_l)

// MAKE GAUSSIAN PROCESS
assume gp = make_gp( 0, se)

// INCORPORATE OBSERVATIONS
observe gp(array x[1],...x[n])= array(y[1],...,y[n])

// INFER HYPER-PARAMETERS
infer mh('hyper, one, 1)))

\end{lstlisting}
\end{minipage}


The first two lines declare the hyper-parameters.
We tag both of them to belong to the ``scope'' \texttt{'hyper}.
These tags are supplied to the inference program (in this case, MH) to specify on which random variables inference should be done.
In this \paperOrChapter, we use MH inference throughout.
Scopes may be further subdivided into blocks, on which block proposals can be made.
In this \paperOrChapter we do not use block proposals; MH inference is done on one variable at a time.

The ASSUME directives describe the GP model: \texttt{sf} and \texttt{l} (corresponding to $\sigma$ and $\ell$) are drawn from independent $\Gamma(1,3)$ distributions.
The squared exponential covariance function can be defined outside the Venture code in a conventional programming language (e.g. Python) and imported as a foreign SP.
In that way, the user can define custom covariance functions using his or her language and libraries of choice, without having to port existing code into Venture's modelling language.
In the above, the factory function \texttt{make-se}, which produces a squared exponential function with the supplied hyperparameters, is imported from Python (we have omitted the Python code).
In the next line \texttt{make-se} is used to produce a covariance function \texttt{SE}, whose (random) hyperparameters are \texttt{l} and \texttt{sf}.
Finally, we declare \texttt{GP} to be a Gaussian process with mean zero and covariance function \texttt{SE}.





{\color{red} I don't know what these two paragraphs mean --Ben}

In the case where hyper-parameters are unknown they can be found deterministically by optimizing the marginal likelihood using a gradient based optimizer. Non-deterministic, Bayesian representations of this case are also known~\citep{neal1997monte}. 

We have already implemented this in listing \ref{alg:gpNeal}. We draw the hyper-parameters from a $\Gamma$-prior for a Bayesian treatment of hyper-parameters. This is simple using the build in stochastic procedure that simulates drawing samples from a gamma distribution.
The program gives rise to a Bayesian representation of GPs, which we will explore in the following.
