We will first introduce common covariance functions (a.k.a. kernels) as they will become important for our models below:

\begin{align}
\text{SE} &= \sigma^2 \exp(-\frac{(x-x^\prime)^2}{2\ell^2}) \label{eq:SE}\\
\text{LIN} &=   \sigma^2(x x^\prime) \label{eq:LIN}\\
\text{C} &=   \sigma^2\label{eq:C}\\
\text{WN} &= \sigma^2 \delta_{x,x^\prime} \label{eq:WN} \\
\text{RQ} &=    \sigma^2 \bigg(1 + \frac{(x - x^\prime)^2}{2 \alpha \ell^2} \bigg)^{-\alpha} \label{eq:RQ} \\
\text{PER} &=  \sigma^2 \exp \bigg( \frac{2 \sin^2 ( \pi (x - x^\prime)/p}{\ell^2} \bigg). \label{eq:PER}
\end{align}
%ToDo: double check what happens with covs, shipped or not
Custom covariance functions can be implemented in python outside of Venture. All of the above will be shipped with Venture in future releases\footnote{The covariance functions will be available as type Venture-Function}.

We demonstrate a simple smoothing \ac{GP} in Venture. The Venture procedure \texttt{make-gp} takes as input a mean function and a covariance function, and outputs a procedure for sampling from a Gaussian process.
In effect, each call to this procedure samples from \eqref{eq:gpsampler} conditioned on the return values of all previous samples.
\texttt{make-gp} allows us to perform GP inference in Venture with only a few lines of code.
We can concisely express a wide variety of GPs: simple smoothing with fixed hyper-parameters, or a prior on hyper-parameters, or a custom covariance function.
Inference on hyper-parameters can be performed using Venture's built-in MH operator or a custom inference strategy.

Venture code to create and sample from a GP with a smoothing kernel and hyperparameters is shown in Listing \ref{alg:VenGP}.

\input{code/code_vengp.tex}


The first two lines declare the hyper-parameters.
We tag both of them to belong to the ``scope'' \texttt{quote(hyper)}.
Scopes may be further subdivided into blocks, on which block proposals can be made. In the program above we assign two blocks, 0 and 1. These tags are supplied to the inference program (in this case, MH) to specify on which random variables inference should be done. In this \paperOrChapter, we use MH inference throughout and do not use block proposals; MH inference is done on one variable at a time.

The \texttt{assume} directives describe the GP model: \texttt{sf} and \texttt{l} (corresponding to $\sigma$ and $\ell$ in the squared exponential covariance function (\ref{eq:SE})) are drawn from independent $\Gamma(1,3)$ distributions (line 1 and 2).
The squared exponential covariance function can be defined outside the Venture code in a conventional programming language (e.g. Python) and imported as a foreign SP.
In that way, the user can define custom covariance functions using his or her language and libraries of choice, without having to port existing code into Venture's modelling language.
In the above, the factory function \texttt{make-squaredexp}, which produces a squared exponential function with the supplied hyperparameters, is imported from Python (line 3, we have omitted the Python code).

Finally, we declare \texttt{GP} to be a Gaussian process with mean zero and covariance function \texttt{SE} (line 4). We observe data (line 5) and take an \ac{MH} step (line 6).






